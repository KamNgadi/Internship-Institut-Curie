{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.42 ðŸš€ Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (Quadro RTX 8000, 48585MiB)\n",
      "Setup complete âœ… (72 CPUs, 250.5 GB RAM, 1870.7/1876.2 GB disk)\n",
      "\n",
      "OS                  Linux-5.15.0-107-generic-x86_64-with-glibc2.29\n",
      "Environment         Linux\n",
      "Python              3.8.10\n",
      "Install             pip\n",
      "RAM                 250.54 GB\n",
      "CPU                 Intel Xeon Gold 5220 2.20GHz\n",
      "CUDA                12.1\n",
      "\n",
      "numpy               âœ… 1.24.4<2.0.0,>=1.23.5\n",
      "matplotlib          âœ… 3.7.5>=3.3.0\n",
      "opencv-python       âœ… 4.8.0.74>=4.6.0\n",
      "pillow              âœ… 10.2.0>=7.1.2\n",
      "pyyaml              âœ… 6.0.1>=5.3.1\n",
      "requests            âœ… 2.31.0>=2.23.0\n",
      "scipy               âœ… 1.10.1>=1.4.1\n",
      "torch               âœ… 2.2.1>=1.8.0\n",
      "torchvision         âœ… 0.17.1>=0.9.0\n",
      "tqdm                âœ… 4.66.2>=4.64.0\n",
      "psutil              âœ… 5.9.8\n",
      "py-cpuinfo          âœ… 9.0.0\n",
      "pandas              âœ… 2.0.3>=1.1.4\n",
      "seaborn             âœ… 0.13.2>=0.11.0\n",
      "ultralytics-thop    âœ… 2.0.0>=2.0.0\n"
     ]
    }
   ],
   "source": [
    "import utils \n",
    "import os, sys, shutil, random\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "import yaml\n",
    "import glob\n",
    "import cv2\n",
    "display.clear_output()\n",
    "!yolo checks\n",
    "HOME = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(input_dir:str, output_dir:str, val_ratio=0.2) -> None:\n",
    "    utils.create_dir_structure(output_dir)\n",
    "    \n",
    "    train_images_dir = os.path.join(input_dir, 'images')\n",
    "    print(f\"train_images_dir: {train_images_dir}\")\n",
    "    train_masks_dir = os.path.join(input_dir, 'masks')\n",
    "    print(f\"train_masks_dir: {train_masks_dir}\")\n",
    "    \n",
    "    categories = ['Arch', 'Blackberry', 'Round']\n",
    "    \n",
    "    for category in categories:\n",
    "        mask_category_dir = os.path.join(train_masks_dir, category)\n",
    "        print(f\"Processing category: {category}\")\n",
    "        \n",
    "       \n",
    "        image_files = sorted(os.listdir(train_images_dir))\n",
    "        image_files = [f for f in image_files if f.lower().endswith(('tif'))]  # Make the extension check case-insensitive\n",
    "        \n",
    "        num_images = len(image_files)\n",
    "        num_val = int(num_images * val_ratio)\n",
    "        \n",
    "        val_images = random.sample(image_files, num_val)\n",
    "        train_images = [img for img in image_files if img not in val_images]\n",
    "        \n",
    "        for img in train_images:\n",
    "            img_name = os.path.basename(img)\n",
    "            src_mask_path = os.path.join(mask_category_dir, img)\n",
    "            dst_mask_path = os.path.join(output_dir, 'train_masks', category, img)\n",
    "            \n",
    "            shutil.copy(src_mask_path, dst_mask_path)\n",
    "        \n",
    "        for img in val_images:\n",
    "            img_name = os.path.basename(img)\n",
    "            src_mask_path = os.path.join(mask_category_dir, img)\n",
    "            dst_mask_path = os.path.join(output_dir, 'val_masks', category, img)\n",
    "\n",
    "            shutil.copy(src_mask_path, dst_mask_path)\n",
    "\n",
    "    print(f\"Category {category} - Train: {len(train_images)}, Val: {len(val_images)}\")\n",
    "\n",
    "    for img in train_images:\n",
    "        img_name = os.path.basename(img)\n",
    "        src_img_path = os.path.join(train_images_dir, img_name)\n",
    "        dst_img_path = os.path.join(output_dir, 'train_images', img_name)\n",
    "        shutil.copy(src_img_path, dst_img_path)\n",
    "\n",
    "    for img in val_images:\n",
    "            img_name = os.path.basename(img)\n",
    "            src_img_path = os.path.join(train_images_dir, img_name)   \n",
    "            dst_img_path = os.path.join(output_dir, 'val_images', img_name)\n",
    "            shutil.copy(src_img_path, dst_img_path)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"train\"\n",
    "output_directory = HOME + \"/input\"\n",
    "split_data(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_double_extension_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.tif.tif'):\n",
    "            new_filename = filename.replace('.tif.tif', '.tif')\n",
    "            os.rename(os.path.join(directory, filename), os.path.join(directory, new_filename))\n",
    "            print(f\"Renamed: {filename} to {new_filename}\")\n",
    "\n",
    "\n",
    "def remove_dm3_extension(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the filename contains '.dm3'\n",
    "        if '.dm3' in filename:\n",
    "            # Create the new filename by removing '.dm3'\n",
    "            new_filename = filename.replace('.dm3', '')\n",
    "            # Construct full file paths\n",
    "            old_file_path = os.path.join(directory, filename)\n",
    "            new_file_path = os.path.join(directory, new_filename)\n",
    "            # Rename the file\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed: {filename} to {new_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "directory_path = HOME +  \"/input/val_masks/Blackberry\"\n",
    "remove_dm3_extension(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import utils\n",
    "\n",
    "\n",
    "def process_masks(mask_paths: str, output_dir: str) -> None:\n",
    "    category_ids = {\n",
    "        \"Arch\": 1,\n",
    "        \"Blackberry\": 2,\n",
    "        \"Round\": 3\n",
    "    }\n",
    "\n",
    "    annotations = []\n",
    "    images = []\n",
    "    image_id = 0\n",
    "    ann_id = 0\n",
    "    MASKS_EXT = 'tif'\n",
    "    ORIGINAL_EXT = 'tif'\n",
    "\n",
    "    for category in category_ids.keys():\n",
    "        for mask_image in glob.glob(os.path.join(mask_paths, category, f'*.{MASKS_EXT}')):\n",
    "            img_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
    "            mask = cv2.imread(mask_image, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            if mask is None:\n",
    "                print(f\"Warning: Mask image {mask_image} could not be read.\")\n",
    "                continue\n",
    "            \n",
    "            # Get image dimensions\n",
    "            height, width = mask.shape[:2]\n",
    "\n",
    "            # Create or find existing image annotation\n",
    "            if img_file_name not in map(lambda img: img['file_name'], images):\n",
    "                image_id += 1\n",
    "                images.append({\n",
    "                    \"id\": image_id,\n",
    "                    \"file_name\": img_file_name,\n",
    "                    \"height\": height,\n",
    "                    \"width\": width\n",
    "                })\n",
    "                image = images[-1]  # The newly added image\n",
    "            else:\n",
    "                image = [element for element in images if element['file_name'] == img_file_name][0]\n",
    "\n",
    "            unique_values = np.unique(mask)\n",
    "            for value in unique_values:\n",
    "                if value == 0:\n",
    "                    continue\n",
    "\n",
    "                object_mask = (mask == value).astype(np.uint8) * 255\n",
    "                polygons = utils.mask_to_polygons(object_mask)\n",
    "\n",
    "                for poly in polygons:\n",
    "                    ann_id += 1\n",
    "                    annotations.append({\n",
    "                        \"id\": ann_id,\n",
    "                        \"image_id\": image['id'],\n",
    "                        \"category_id\": category_ids[category],\n",
    "                        \"segmentation\": [poly],\n",
    "                        \"area\": cv2.contourArea(np.array(poly).reshape(-1, 2)),\n",
    "                        \"bbox\": list(cv2.boundingRect(np.array(poly).reshape(-1, 2))),\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "\n",
    "    coco_output = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": [{\"id\": value, \"name\": key, \"supercategory\": key} for key, value in category_ids.items()]\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(output_dir, 'coco_annotations.json'), 'w') as f:\n",
    "        json.dump(coco_output, f)\n",
    "\n",
    "    print(\"Created %d annotations for images in folder: %s\" % (len(annotations), mask_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME\n",
    "train_masks_path= HOME+  \"/input/train_masks\"\n",
    "train_output_dir =HOME + \"/input/train_images\"\n",
    "process_masks(mask_paths=train_masks_path, output_dir=train_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_masks_path= HOME+  \"/input/val_masks\"\n",
    "val_output_dir =HOME + \"/input/val_images\"\n",
    "process_masks(mask_paths=val_masks_path, output_dir=val_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo(input_images_path, input_json_path, output_images_path, output_labels_path):\n",
    "    # Open JSON file containing image annotations\n",
    "    f = open(input_json_path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Create directories for output images and labels\n",
    "    os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_labels_path, exist_ok=True)\n",
    "\n",
    "    # List to store filenames\n",
    "    file_names = []\n",
    "    for filename in os.listdir(input_images_path):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            source = os.path.join(input_images_path, filename)\n",
    "            destination = os.path.join(output_images_path, filename)\n",
    "            shutil.copy(source, destination)\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Function to get image annotations\n",
    "    def get_img_ann(image_id):\n",
    "        return [ann for ann in data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "    # Function to get image data\n",
    "    def get_img(filename):\n",
    "        return next((img for img in data['images'] if img['file_name'] == filename), None)\n",
    "\n",
    "    # Iterate through filenames and process each image\n",
    "    for filename in file_names:\n",
    "        img = get_img(filename)\n",
    "        if img is None:\n",
    "            print(f\"Warning: No annotation found for image {filename}\")\n",
    "            continue  # Skip this image if no annotation is found\n",
    "        \n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # Write normalized polygon data to a text file\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_path, f\"{os.path.splitext(filename)[0]}.txt\"), \"a\") as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")\n",
    "\n",
    "\n",
    "# Function to create a YAML file for the dataset\n",
    "def create_yaml(input_json_path, output_yaml_path, train_path, val_path, test_path=None):\n",
    "    with open(input_json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract the category names\n",
    "    names = [category['name'] for category in data['categories']]\n",
    "    \n",
    "    # Number of classes\n",
    "    nc = len(names)\n",
    "\n",
    "    # Create a dictionary with the required content\n",
    "    yaml_data = {\n",
    "        'names': names,\n",
    "        'nc': nc,\n",
    "        'test': test_path if test_path else '',\n",
    "        'train': train_path,\n",
    "        'val': val_path\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a YAML file\n",
    "    with open(output_yaml_path, 'w') as file:\n",
    "        yaml.dump(yaml_data, file, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert images to YOLO format\n",
    "def convert_to_yolo(input_images_path, input_json_path, output_images_path, output_labels_path):\n",
    "    # Open JSON file containing image annotations\n",
    "    f = open(input_json_path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Create directories for output images and labels\n",
    "    os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_labels_path, exist_ok=True)\n",
    "\n",
    "    # List to store filenames\n",
    "    file_names = []\n",
    "    for filename in os.listdir(input_images_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp','.tif', '.tiff')):\n",
    "            source = os.path.join(input_images_path, filename)\n",
    "            destination = os.path.join(output_images_path, filename)\n",
    "            shutil.copy(source, destination)\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Function to get image annotations\n",
    "    def get_img_ann(image_id):\n",
    "        return [ann for ann in data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "    # Function to get image data\n",
    "    def get_img(filename):\n",
    "        return next((img for img in data['images'] if img['file_name'] == filename), None)\n",
    "\n",
    "    # Iterate through filenames and process each image\n",
    "    for filename in file_names:\n",
    "        img = get_img(filename)\n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # Write normalized polygon data to a text file\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_path, f\"{os.path.splitext(filename)[0]}.txt\"), \"a\") as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input_path = \"input/\"\n",
    "base_output_path = \"yolo_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing training dataset \n",
    "convert_to_yolo(\n",
    "    input_images_path=os.path.join(base_input_path, \"train_images\"),\n",
    "    input_json_path=os.path.join(base_input_path, \"train_images/coco_annotations.json\"),\n",
    "    output_images_path=os.path.join(base_output_path, \"train/images\"),\n",
    "    output_labels_path=os.path.join(base_output_path, \"train/labels\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing validation dataset (if needed)\n",
    "convert_to_yolo(\n",
    "    input_images_path=os.path.join(base_input_path, \"val_images\"),\n",
    "    input_json_path=os.path.join(base_input_path, \"val_images/coco_annotations.json\"),\n",
    "    output_images_path=os.path.join(base_output_path, \"valid/images\"),\n",
    "    output_labels_path=os.path.join(base_output_path, \"valid/labels\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the YAML configuration file\n",
    "create_yaml(\n",
    "    input_json_path=os.path.join(base_input_path, \"train_images/coco_annotations.json\"),\n",
    "    output_yaml_path=os.path.join(base_output_path, \"data.yaml\"),\n",
    "    train_path=\"train/images\",\n",
    "    val_path=\"valid/images\",\n",
    "    test_path='../test/images'  # or None if not applicable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_with_annotations(image_paths, annotation_paths):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    \n",
    "    for ax, img_path, ann_path in zip(axs.ravel(), image_paths, annotation_paths):\n",
    "        # Load image using OpenCV and convert it from BGR to RGB color space\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_h, img_w, _ = image.shape\n",
    "        \n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')  # Turn off the axes\n",
    "\n",
    "        # Open the annotation file and process each line\n",
    "        with open(ann_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                category_id = int(parts[0])\n",
    "                color = tuple(np.random.rand(3))  # Generate a random RGB color\n",
    "                polygon = [float(coord) for coord in parts[1:]]\n",
    "                polygon = [coord * img_w if i % 2 == 0 else coord * img_h for i, coord in enumerate(polygon)]\n",
    "                polygon = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
    "                patch = patches.Polygon(polygon, closed=True, edgecolor=color, fill=False)\n",
    "                ax.add_patch(patch)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get all image files\n",
    "image_dir = \"yolo_dataset/train/images/\"\n",
    "annotation_dir = \"yolo_dataset/train/labels/\"\n",
    "all_image_files = [f for f in os.listdir(image_dir) if f.endswith('.tif')]\n",
    "random_image_files = random.sample(all_image_files, 4)\n",
    "\n",
    "# Get corresponding annotation files\n",
    "image_paths = [os.path.join(image_dir, f) for f in random_image_files]\n",
    "annotation_paths = [os.path.join(annotation_dir, f.replace(\".tif\", \".txt\")) for f in random_image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images_with_annotations(image_paths, annotation_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.42 ðŸš€ Python-3.8.10 torch-2.2.1+cu121 CUDA:0 (Quadro RTX 8000, 48585MiB)\n",
      "Setup complete âœ… (72 CPUs, 250.5 GB RAM, 1870.7/1876.2 GB disk)\n",
      "\n",
      "OS                  Linux-5.15.0-107-generic-x86_64-with-glibc2.29\n",
      "Environment         Linux\n",
      "Python              3.8.10\n",
      "Install             pip\n",
      "RAM                 250.54 GB\n",
      "CPU                 Intel Xeon Gold 5220 2.20GHz\n",
      "CUDA                12.1\n",
      "\n",
      "numpy               âœ… 1.24.4<2.0.0,>=1.23.5\n",
      "matplotlib          âœ… 3.7.5>=3.3.0\n",
      "opencv-python       âœ… 4.8.0.74>=4.6.0\n",
      "pillow              âœ… 10.2.0>=7.1.2\n",
      "pyyaml              âœ… 6.0.1>=5.3.1\n",
      "requests            âœ… 2.31.0>=2.23.0\n",
      "scipy               âœ… 1.10.1>=1.4.1\n",
      "torch               âœ… 2.2.1>=1.8.0\n",
      "torchvision         âœ… 0.17.1>=0.9.0\n",
      "tqdm                âœ… 4.66.2>=4.64.0\n",
      "psutil              âœ… 5.9.8\n",
      "py-cpuinfo          âœ… 9.0.0\n",
      "pandas              âœ… 2.0.3>=1.1.4\n",
      "seaborn             âœ… 0.13.2>=0.11.0\n",
      "ultralytics-thop    âœ… 2.0.0>=2.0.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m-seg.yaml\") # build a new model from yaml\n",
    "model = YOLO(\"yolov8m-seg.pt\") # transfer weights fro a pre-trained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('yolo_dataset/data.yaml', 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanofi_projct = \"yolo_dataset/results\"\n",
    "name = \"125_epochs_seg_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(data='yolo_dataset/data.yaml',\n",
    "                    project=sanofi_projct,\n",
    "                    name=name,\n",
    "                    epochs=125\n",
    "                    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, data_dir, ious):\n",
    "\n",
    "    #ious = np.linspace(.5,1,50)\n",
    "    precision = []\n",
    "    recall = []\n",
    "    jac_idx = []\n",
    "    for io in ious:\n",
    "        tp_eval = YOLO(model)\n",
    "        metrics = tp_eval.val(data= data_dir,\n",
    "                              iou=io,\n",
    "                              device=0\n",
    "                              )\n",
    "        precision.append(metrics.results_dict[\"metrics/precision(B)\"])\n",
    "        recall.append(metrics.results_dict[\"metrics/recall(B)\"])\n",
    "        conf_mtrx = metrics.confusion_matrix\n",
    "        j_idx = conf_mtrx.matrix[0][0]/conf_mtrx.matrix.sum()\n",
    "        jac_idx.append(j_idx)\n",
    "    return jac_idx, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_idx, precision, recall = evaluation(model=\"yolo_dataset/results/125_epochs_seg_l2/weights/best.pt\", data_dir=\"yolo_dataset/data.yaml\", ious=np.linspace(.5,1,50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/kamenan/Documents/Stage Dev Deep Learning/YOLOV8 evaluation/sanofi_test/test_img/200L_GBD_50K_029.dm3.tif.tif: 640x640 3 Archs, 3 Blackberrys, 24 Rounds, 24.2ms\n",
      "Speed: 5.3ms preprocess, 24.2ms inference, 154.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model1 = YOLO(\"yolo_dataset/results/125_epochs_seg_l2/weights/best.pt\")\n",
    "\n",
    "image = \"/home/kamenan/Documents/Stage Dev Deep Learning/YOLOV8 evaluation/sanofi_test/test_img/200L_GBD_50K_029.dm3.tif.tif\"\n",
    "\n",
    "results = model1.predict(image, conf=0.5, show_labels=True, show_boxes=True, show=True)  #Adjust conf threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "try:\n",
    "    img = cv2.imread(\"/home/kamenan/Documents/Stage Dev Deep Learning/YOLOV8 evaluation/sanofi_test/test_img/200L_GBD_50K_029.dm3.tif.tif\")\n",
    "    h, w, c = img.shape\n",
    "except cv2.error as e:\n",
    "    print(f\"Failed to load image: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Create the YOLOv8 model\n",
    "try:\n",
    "    model = YOLO(\"yolo_dataset/results/125_epochs_seg_l2/weights/best.pt\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Perform the prediction\n",
    "img2 = cv2.resize(img, (640,640))\n",
    "results = model.predict(img2, iou=.5)\n",
    "\n",
    "if(results[0].masks is not None):\n",
    "    # Get the size of the original image (height, width, channels)\n",
    "    h2, w2, c2 = results[0].orig_img.shape\n",
    "    print((w2, h2))\n",
    "\n",
    "    # Create a black image with the same size as the original image\n",
    "    black_img = np.zeros_like(results[0].orig_img)\n",
    "    black_img = black_img[:,:,0]\n",
    "    print(black_img.shape)\n",
    "    # Create a copy of the original image to layer the masks on\n",
    "    layered_img = results[0].orig_img.copy()\n",
    "\n",
    "    # Loop over all masks in the results\n",
    "    for i, mask_raw in enumerate(results[0].masks):\n",
    "        # Convert mask to single channel image\n",
    "        mask_raw = mask_raw.cpu().data.numpy().transpose(1, 2, 0)\n",
    "\n",
    "        # Resize the mask to the same size as the image (can probably be removed if image is the same size as the model)\n",
    "        mask = cv2.resize(mask_raw, (640, 640))\n",
    "\n",
    "        # Convert the mask to the correct data type\n",
    "        mask = mask.astype(np.uint8)\n",
    "        #print(mask.shape)\n",
    "\n",
    "        #multiply by i+1\n",
    "        mask = mask*(i+1)\n",
    "\n",
    "        #add mask to black_img\n",
    "        black_img = np.maximum(black_img, mask)\n",
    "        #black_img = black_img + mask\n",
    "        \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        exit()\n",
    "\n",
    "# Close all windows\n",
    "#cv2.imwrite(\"mask_raw.png\", mask_raw)\n",
    "#cv2.imwrite(\"mask.png\", mask)\n",
    "black_img = cv2.resize(black_img, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "cv2.imwrite(\"black_img.png\", black_img)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_masks(data_dir: str, image_dir: str, model: str) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Get the segmented masks with a given infered model\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "           data_dir: Absolute path to image to segment\n",
    "           image_dir: relative path to image to segment\n",
    "           model: Model to make the inference\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # set the current directory to the image directory\n",
    "    #os.chdir(image_dir)\n",
    "\n",
    "    # create segmented masks directory\n",
    "    seg_masks_dir = os.path.join(data_dir, 'seg_masks')\n",
    "    if not os.path.exists(seg_masks_dir):\n",
    "        try:\n",
    "            os.makedirs(seg_masks_dir, exist_ok=True)\n",
    "        except os.error as e:\n",
    "            print(f'Same directory exist:{e}')\n",
    "            exit()\n",
    "    # set the path to the image directory\n",
    "    img_dir = os.path.join(data_dir, image_dir)\n",
    "\n",
    "    # iterate over all files in the test image directory\n",
    "    for file in os.listdir(img_dir):\n",
    "        # contruct full file path\n",
    "        file_path = os.path.join(img_dir, file)\n",
    "\n",
    "        # check if the file is image\n",
    "        if os.path.isfile(file_path) and file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp','.tif', '.tiff')):\n",
    "            # read the image with OpenCV\n",
    "            try:\n",
    "                img = cv2.imread(file_path)\n",
    "                h, w, _ = img.shape\n",
    "            except cv2.error as e:\n",
    "                print(f\"Failed to load image: {e}\")\n",
    "                exit()\n",
    "\n",
    "        # create the YOLOV8 \n",
    "        try:\n",
    "            mdel = YOLO(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load model: {e}\")\n",
    "            exit()\n",
    "        \n",
    "        # Perform the prediction\n",
    "        img2 = cv2.resize(img, (640,640))\n",
    "        #img2 = cv2.resize(img, (img.shape[1], img.shape[0]))\n",
    "        #imgsz = (img2.shape[0], img2.shape[0])\n",
    "        results = mdel.predict(img2, iou=.5)\n",
    "\n",
    "        if(results[0].masks is not None):\n",
    "            # Get the size of the original image (height, width, channels)\n",
    "            h2, w2, c2 = results[0].orig_img.shape\n",
    "\n",
    "            # Create a black image with the same size as the original image\n",
    "            black_img = np.zeros_like(results[0].orig_img)\n",
    "            black_img = black_img[:,:,0]\n",
    "            \n",
    "            # Create a copy of the original image to layer the masks on\n",
    "            #layered_img = results[0].orig_img.copy()\n",
    "\n",
    "            # Loop over all masks in the results\n",
    "            for i, mask_raw in enumerate(results[0].masks):\n",
    "                # Convert mask to single channel image\n",
    "                mask_raw = mask_raw.cpu().data.numpy().transpose(1, 2, 0)\n",
    "\n",
    "                # Resize the mask to the same size as the image (can probably be removed if image is the same size as the model)\n",
    "                mask = cv2.resize(mask_raw, (w2, h2))\n",
    "\n",
    "                # Convert the mask to the correct data type\n",
    "                mask = mask.astype(np.uint16)\n",
    "\n",
    "                #multiply by i+1\n",
    "                mask = mask*(i+1)\n",
    "\n",
    "                #add mask to black_img\n",
    "                black_img = np.maximum(black_img, mask)\n",
    "\n",
    "            # Break the loop if 'q' key is pressed\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                exit()\n",
    "        \n",
    "        name, ext = os.path.splitext(file)\n",
    "\n",
    "        # set the path to the segmented mask with the same naming system like images\n",
    "        seg_mask = os.path.join(seg_masks_dir, seg_masks_dir + '/' + name.replace(\"img\", \"masks\") + \"_seg.\" + ext)\n",
    "        \n",
    "        # Close all windows\n",
    "        black_img = cv2.resize(black_img, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "        cv2.imwrite(seg_mask, black_img)\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
